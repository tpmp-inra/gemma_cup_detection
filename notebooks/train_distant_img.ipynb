{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "voluntary-worth",
   "metadata": {},
   "source": [
    "# Gemma cup detection V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-thinking",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead, RegionProposalNetwork\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from engine import train_one_epoch, evaluate\n",
    "import transforms as T\n",
    "\n",
    "from skimage import io, transform\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image as IpImage\n",
    "from IPython.display import display\n",
    "from ipywidgets import Button, HBox, VBox\n",
    "from PIL import Image as PilImage\n",
    "\n",
    "from loaders import (\n",
    "    GemmaDataset, \n",
    "    get_train_transform, \n",
    "    get_valid_transform, \n",
    "    Averager, \n",
    "    format_prediction_string, \n",
    "    show_predictions,\n",
    "    predict_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-shelf",
   "metadata": {},
   "source": [
    "## Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"..\", \"data_in\")\n",
    "images_path =os.path.join(data_path, \"images\")\n",
    "\n",
    "test_index = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-light",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-macintosh",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-bride",
   "metadata": {},
   "source": [
    "#### Build test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = GemmaDataset(\n",
    "    csv=pd.read_csv(os.path.join(data_path, \"boxes_final.csv\")),\n",
    "    images_path=images_path,\n",
    ")\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-white",
   "metadata": {},
   "source": [
    "#### Test boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.load_boxes(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.load_boxes(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.load_boxes(test_index)[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-switch",
   "metadata": {},
   "source": [
    "#### Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ds.load_image(test_index)\n",
    "io.imshow(img) \n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-filing",
   "metadata": {},
   "source": [
    "#### Test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.get_by_sample_name(\"b0KXwBrE57rCtnxjL2jKk0AXGwCI.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_sample = widgets.Dropdown(options=sorted(ds.images))\n",
    "\n",
    "image_output = widgets.Output(layout={\"border\": \"1px solid black\"})\n",
    "rects_output = widgets.Output(layout={\"border\": \"1px solid black\"})\n",
    "\n",
    "\n",
    "def print_final_rects(change):\n",
    "    image_output.clear_output()\n",
    "    rects_output.clear_output()\n",
    "    \n",
    "    image, targets, _ = ds.get_by_sample_name(change.new)\n",
    "                             \n",
    "    boxes = targets['boxes'].cpu().numpy().astype(np.int32)\n",
    "    image = image.permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    with image_output:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "        ax.set_axis_off()\n",
    "        for box in boxes:\n",
    "            ax.add_patch(\n",
    "                patches.Rectangle(\n",
    "                    (box[0], box[1]), \n",
    "                    box[2] - box[0], \n",
    "                    box[3] - box[1],\n",
    "                    linewidth=2, \n",
    "                    edgecolor=\"r\", \n",
    "                    facecolor=\"none\",\n",
    "                )\n",
    "            )\n",
    "        ax.imshow(image)\n",
    "        plt.show()\n",
    "    \n",
    "    with rects_output:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                [box for box in boxes], \n",
    "                columns=[\"x1\", \"y1\", \"x2\", \"y2\"],                \n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "dd_sample.observe(print_final_rects, names=\"value\")\n",
    "display(dd_sample, HBox([image_output, rects_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-rating",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2  # 1 class (wheat) + background\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-finger",
   "metadata": {},
   "source": [
    "## Build data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-proceeding",
   "metadata": {},
   "source": [
    "### Create train and test dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-motor",
   "metadata": {},
   "source": [
    "#### Load and clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"boxes.csv\"))\n",
    "df = df[(df.width != 0) & (df.height != 0)].reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-disclaimer",
   "metadata": {},
   "source": [
    "#### Split dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes: tuple = (0.8, 0.20)\n",
    "dataset_size = len(list(df.filename.unique()))\n",
    "indices = [ i for i in list(df.filename.unique())]\n",
    "\n",
    "split_train = int(np.floor(sizes[0] * dataset_size))\n",
    "split_test = int(np.floor(sizes[1] * dataset_size)) + split_train\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = (\n",
    "    indices[:split_train],\n",
    "    indices[split_train:split_test],\n",
    ")\n",
    "\n",
    "df_train = df[df.filename.isin(train_indices)]\n",
    "df_test = df[df.filename.isin(test_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop_duplicates(subset=[\"filename\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop_duplicates(subset=[\"filename\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-static",
   "metadata": {},
   "source": [
    "#### Look for leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for leakage\n",
    "pd.merge(\n",
    "    df_train,\n",
    "    df_test,\n",
    "    on=list(df_test.columns),\n",
    "    how=\"inner\",\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-gothic",
   "metadata": {},
   "source": [
    "#### Ensure images are only in one set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_train.filename.to_list()).intersection(set(df_test.filename.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-internship",
   "metadata": {},
   "source": [
    "### Build datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GemmaDataset(\n",
    "    csv=df_train, \n",
    "    transform=get_train_transform(),\n",
    "    images_path=images_path,\n",
    ")\n",
    "valid_dataset = GemmaDataset(\n",
    "    csv=df_test,\n",
    "    transform=get_valid_transform(),\n",
    "    images_path=images_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    train_dataset[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-surface",
   "metadata": {},
   "source": [
    "### Build loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-parliament",
   "metadata": {},
   "source": [
    "## Select device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-launch",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets, image_ids = next(iter(train_data_loader))\n",
    "images = list(image.to(device) for image in images)\n",
    "targets = [{k: v.to(device) for k, v in t.items()} for t in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\n",
    "sample = images[0].permute(1,2,0).cpu().numpy()\n",
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "for box in boxes:\n",
    "    cv2.rectangle(\n",
    "        sample,\n",
    "        (box[0], box[1]),\n",
    "        (box[2], box[3]),\n",
    "        (220, 0, 0), \n",
    "        3\n",
    "    )\n",
    "\n",
    "ax.set_axis_off()\n",
    "ax.imshow(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-beast",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "lr_scheduler = None\n",
    "\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = Averager()\n",
    "itr = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_hist.reset()\n",
    "    \n",
    "    for images, targets, image_ids in train_data_loader:\n",
    "        \n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        loss_hist.send(loss_value)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % 10 == 0:\n",
    "            print(f\"Iteration #{itr} loss: {loss_value}\")\n",
    "\n",
    "        itr += 1\n",
    "    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    print(f\"Epoch #{epoch} loss: {loss_hist.value}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-maple",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets, image_ids = next(iter(valid_data_loader))\n",
    "images, targets, image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict_loader(\n",
    "    model=model,\n",
    "    loader=valid_data_loader,\n",
    "    device=device,\n",
    "    detection_threshold=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(list(results.values()), columns=['image_id', 'PredictionString', \"scores\", \"boxes\"])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_loader = iter(valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(*next(iter_loader), device, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-shade",
   "metadata": {},
   "source": [
    "## Save state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_output_path = os.path.join(\"..\", \"models\",datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"state_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    model.state_dict(), \n",
    "    state_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-silence",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_path = os.path.join(\"..\", \"models\",datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-cleveland",
   "metadata": {},
   "source": [
    "## Predict with stored data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-selection",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(os.path.join(\"..\", \"models\", \"default_model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-sudan",
   "metadata": {},
   "source": [
    "### Predict rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_loader(\n",
    "    model=loaded_model,\n",
    "    loader=valid_data_loader,\n",
    "    device=device,\n",
    "    detection_threshold=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-fraction",
   "metadata": {},
   "source": [
    "### View predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_loader = iter(valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(*next(predict_loader), device, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-seventh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
