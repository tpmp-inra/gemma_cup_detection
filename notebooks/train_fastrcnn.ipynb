{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "moved-ghana",
   "metadata": {},
   "source": [
    "# Gemma cup detection V2\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-class",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7236073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image as IpImage\n",
    "from IPython.display import display\n",
    "from ipywidgets import HBox\n",
    "\n",
    "import loaders as lds\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-washington",
   "metadata": {},
   "source": [
    "## Define Constants"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18958dd7",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"..\").joinpath(\"data_in\")\n",
    "images_path = data_path.joinpath(\"images\")\n",
    "dataset_path = Path(\"..\").joinpath(\"data_in\", \"datasets\")\n",
    "\n",
    "data_path.is_dir(), images_path.is_dir(), dataset_path.is_dir()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f28c93a",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 1024\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f802cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_device(force=None):\n",
    "    return force if force is not None else(\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_built() is True\n",
    "    else \"cuda\"\n",
    "    if torch.backends.cuda.is_built()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "get_device()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "finite-dispatch",
   "metadata": {},
   "source": [
    "## Build Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f93a5f64",
   "metadata": {},
   "source": [
    "### Load CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(dataset_path.joinpath(\"train.csv\"))\n",
    "val = pd.read_csv(dataset_path.joinpath(\"val.csv\"))\n",
    "test = pd.read_csv(dataset_path.joinpath(\"test.csv\"))\n",
    "\n",
    "train.shape, val.shape, test.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16f66fb0",
   "metadata": {},
   "source": [
    "### Build Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a6c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = lds.GemmaDataset(\n",
    "    csv=train,\n",
    "    images_path=images_path,\n",
    "    transform=lds.get_test_image_transform(image_size=image_size),\n",
    ")\n",
    "\n",
    "val_dataset = lds.GemmaDataset(\n",
    "    csv=val,\n",
    "    images_path=images_path,\n",
    "    transform=lds.get_test_image_transform(image_size=image_size),\n",
    ")\n",
    "\n",
    "test_dataset = lds.GemmaDataset(\n",
    "    csv=test,\n",
    "    images_path=images_path,\n",
    "    transform=lds.get_test_image_transform(image_size=image_size),\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9dba22b9",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = train.sample(n=1).filename.to_list()[0]\n",
    "\n",
    "lds.make_patches_grid(\n",
    "    images=[train_dataset.draw_image_with_boxes(filename=file_name) for _ in range(12)],\n",
    "    row_count=3,\n",
    "    col_count=4,\n",
    "    figsize=(10, 7.5),\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "convertible-jewel",
   "metadata": {},
   "source": [
    "## Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "ds_tst = lds.GemmaDataset(\n",
    "    csv=train.sample(n=10),\n",
    "    images_path=images_path,\n",
    "    transform=lds.get_train_transform(image_size=image_size),\n",
    ")\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    lds.GemmaDataset(\n",
    "        csv=train,\n",
    "        images_path=images_path,\n",
    "        transform=lds.get_train_transform(image_size=image_size),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    lds.GemmaDataset(\n",
    "        csv=val,\n",
    "        images_path=images_path,\n",
    "        transform=lds.get_train_transform(image_size=image_size),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    lds.GemmaDataset(\n",
    "        csv=test,\n",
    "        images_path=images_path,\n",
    "        transform=lds.get_train_transform(image_size=image_size),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97197866-1444-41b1-ac1b-55f4746a0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader.dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "premium-amount",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_data_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "boxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\n",
    "sample = images[0].permute(1,2,0).cpu().numpy()\n",
    "boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-jimmy",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a5b79d5",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb3d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images, targets = tuple(zip(*batch))\n",
    "    images = torch.stack(images)\n",
    "    images = images.float()\n",
    "\n",
    "    boxes = [target[\"boxes\"].float() for target in targets]\n",
    "    labels = [target[\"labels\"].float() for target in targets]\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaCupDetector(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int,\n",
    "        learning_rate: float,\n",
    "        max_epochs: int,\n",
    "        train_data: pd.DataFrame,\n",
    "        val_data: pd.DataFrame,\n",
    "        test_data: pd.DataFrame,\n",
    "        train_augmentations: A.Compose,\n",
    "        val_augmentations: A.Compose,\n",
    "        num_workers: int = 0,\n",
    "        accumulate_grad_batches: int = 3,\n",
    "        selected_device: str = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.batch_size = batch_size\n",
    "        self.selected_device = selected_device\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_workers = num_workers\n",
    "        self.max_epochs = max_epochs\n",
    "        self.accumulate_grad_batches = accumulate_grad_batches\n",
    "\n",
    "        # dataframes\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "        # albumentations\n",
    "        self.train_augmentations = train_augmentations\n",
    "        self.val_augmentations = val_augmentations\n",
    "\n",
    "        # Model\n",
    "        self.model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "            pretrained=True\n",
    "        )\n",
    "        num_classes = 2  # 1 class (wheat) + background\n",
    "        # get number of input features for the classifier\n",
    "        in_features = self.model.roi_heads.box_predictor.cls_score.in_features\n",
    "        # replace the pre-trained head with a new one\n",
    "        self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            lds.GemmaDataset(\n",
    "                csv=self.train_data,\n",
    "                images_path=images_path,\n",
    "                transform=self.train_augmentations,\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=collate_fn,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            lds.GemmaDataset(\n",
    "                csv=self.train_data,\n",
    "                images_path=images_path,\n",
    "                transform=self.val_augmentations,\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=collate_fn,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            lds.GemmaDataset(\n",
    "                csv=self.train_data,\n",
    "                images_path=images_path,\n",
    "                transform=self.val_augmentations,\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=collate_fn,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def step_(self, batch, batch_index, loss_type):\n",
    "        x, y = batch\n",
    "        # x, y = x.unsqueeze(0), [y]\n",
    "        loss_dict = self.model(x, y)\n",
    "        print(loss_dict)\n",
    "        losses = torch.tensor([loss for loss in loss_dict.values()])\n",
    "        self.log_dict({f\"{loss_type}_loss\": losses.mean()})\n",
    "        return losses.sum()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step_(batch=batch, batch_index=batch_idx, loss_type=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step_(batch=batch, batch_index=batch_idx, loss_type=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step_(batch=batch, batch_index=batch_idx, loss_type=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b02b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GemmaCupDetector(\n",
    "    batch_size=1,\n",
    "    learning_rate=1e5,\n",
    "    max_epochs=1,\n",
    "    train_data=train,\n",
    "    val_data=val,\n",
    "    test_data=test,\n",
    "    train_augmentations=lds.get_train_transform(image_size=image_size),\n",
    "    val_augmentations=lds.get_valid_transform(image_size=image_size),\n",
    "    num_workers=1,\n",
    "    accumulate_grad_batches=1,\n",
    "    selected_device=get_device(),\n",
    ")\n",
    "\n",
    "\n",
    "dl_tst = DataLoader(\n",
    "    lds.GemmaDataset(\n",
    "        csv=train,\n",
    "        images_path=images_path,\n",
    "        transform=lds.get_train_transform(image_size=image_size),\n",
    "    ),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "model.step_(next(iter(dl_tst)), 0, \"\")\n",
    "\n",
    "# ds_tst[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fadf48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import DeviceStatsMonitor\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    max_epochs=model.max_epochs,\n",
    "    log_every_n_steps=5,\n",
    "    callbacks=[\n",
    "        RichProgressBar(),\n",
    "        EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=15, min_delta=0.0005),\n",
    "        DeviceStatsMonitor(),\n",
    "        ModelCheckpoint(\n",
    "            save_top_k=3,\n",
    "            monitor=\"val_loss\",\n",
    "            auto_insert_metric_name=True,\n",
    "            filename=\"{epoch}-{step}-{train_loss}-{val_loss}\",\n",
    "        ),\n",
    "    ],\n",
    "    accumulate_grad_batches=model.accumulate_grad_batches,\n",
    "    # auto_scale_batch_size=\"binsearch\",\n",
    "    # Debug\n",
    "    # fast_dev_run=True,\n",
    "    # overfit_batches=10,\n",
    "    # detect_anomaly=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf303a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5df8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e7f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.roi_heads.box_predictor.cls_score.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c57563",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2  # 1 class (wheat) + background\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242785c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import engine\n",
    "\n",
    "device = get_device(\"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(\n",
    "    [p for p in model.parameters() if p.requires_grad], \n",
    "    lr=0.005, \n",
    "    momentum=0.9, \n",
    "    weight_decay=0.0005\n",
    ")\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "# lr_scheduler = None\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    engine.train_one_epoch(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_data_loader,\n",
    "        device=device,\n",
    "        epoch=epoch,\n",
    "        print_freq=100,\n",
    "    )\n",
    "    lr_scheduler.step()\n",
    "    engine.evaluate(model, valid_data_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-nursing",
   "metadata": {},
   "source": [
    "## Save state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_output_path = os.path.join(\"..\", \"models\",datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"state_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    model.state_dict(), \n",
    "    state_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-joshua",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_path = os.path.join(\"..\", \"models\",datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801d5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "f85b9c9cb55507c7257ec44526ed60e483c5f29fa824dc52c2852767efcd221e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
