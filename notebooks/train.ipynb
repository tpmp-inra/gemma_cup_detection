{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "moved-ghana",
   "metadata": {},
   "source": [
    "# Gemma cup detection V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-class",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image as IpImage\n",
    "from IPython.display import display\n",
    "from ipywidgets import HBox\n",
    "\n",
    "from loaders import (\n",
    "    GemmaDataset, \n",
    "    get_train_transform, \n",
    "    get_valid_transform, \n",
    "    Averager, \n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-washington",
   "metadata": {},
   "source": [
    "## Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"..\", \"data_in\")\n",
    "images_path =os.path.join(data_path, \"images\")\n",
    "\n",
    "test_index = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-dispatch",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-committee",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-storage",
   "metadata": {},
   "source": [
    "#### Build test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = GemmaDataset(\n",
    "    csv=pd.read_csv(os.path.join(data_path, \"boxes_final.csv\")),\n",
    "    images_path=images_path,\n",
    ")\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-gasoline",
   "metadata": {},
   "source": [
    "#### Test boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.load_boxes(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.load_boxes(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.load_boxes(test_index)[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-april",
   "metadata": {},
   "source": [
    "#### Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ds.load_image(test_index)\n",
    "io.imshow(img) \n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-extra",
   "metadata": {},
   "source": [
    "#### Test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.get_by_sample_name(\"b0KXwBrE57rCtnxjL2jKk0AXGwCI.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_sample = widgets.Dropdown(options=sorted(ds.images))\n",
    "\n",
    "image_output = widgets.Output(layout={\"border\": \"1px solid black\"})\n",
    "rects_output = widgets.Output(layout={\"border\": \"1px solid black\"})\n",
    "\n",
    "\n",
    "def print_final_rects(change):\n",
    "    image_output.clear_output()\n",
    "    rects_output.clear_output()\n",
    "    \n",
    "    image, targets, _ = ds.get_by_sample_name(change.new)\n",
    "                             \n",
    "    boxes = targets['boxes'].cpu().numpy().astype(np.int32)\n",
    "    image = image.permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    with image_output:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "        ax.set_axis_off()\n",
    "        for box in boxes:\n",
    "            ax.add_patch(\n",
    "                patches.Rectangle(\n",
    "                    (box[0], box[1]), \n",
    "                    box[2] - box[0], \n",
    "                    box[3] - box[1],\n",
    "                    linewidth=2, \n",
    "                    edgecolor=\"r\", \n",
    "                    facecolor=\"none\",\n",
    "                )\n",
    "            )\n",
    "        ax.imshow(image)\n",
    "        plt.show()\n",
    "    \n",
    "    with rects_output:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                [box for box in boxes], \n",
    "                columns=[\"x1\", \"y1\", \"x2\", \"y2\"],                \n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "dd_sample.observe(print_final_rects, names=\"value\")\n",
    "display(dd_sample, HBox([image_output, rects_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-jewel",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2  # 1 class (wheat) + background\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-native",
   "metadata": {},
   "source": [
    "## Build data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-cursor",
   "metadata": {},
   "source": [
    "### Create train and test dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-donor",
   "metadata": {},
   "source": [
    "#### Load and clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"boxes.csv\"))\n",
    "df = df[(df.width != 0) & (df.height != 0)].reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-austria",
   "metadata": {},
   "source": [
    "#### Split dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes: tuple = (0.8, 0.20)\n",
    "dataset_size = len(list(df.filename.unique()))\n",
    "indices = [ i for i in list(df.filename.unique())]\n",
    "\n",
    "split_train = int(np.floor(sizes[0] * dataset_size))\n",
    "split_test = int(np.floor(sizes[1] * dataset_size)) + split_train\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = (\n",
    "    indices[:split_train],\n",
    "    indices[split_train:split_test],\n",
    ")\n",
    "\n",
    "df_train = df[df.filename.isin(train_indices)]\n",
    "df_test = df[df.filename.isin(test_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop_duplicates(subset=[\"filename\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop_duplicates(subset=[\"filename\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-kennedy",
   "metadata": {},
   "source": [
    "#### Look for leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for leakage\n",
    "pd.merge(\n",
    "    df_train,\n",
    "    df_test,\n",
    "    on=list(df_test.columns),\n",
    "    how=\"inner\",\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-amateur",
   "metadata": {},
   "source": [
    "#### Ensure images are only in one set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_train.filename.to_list()).intersection(set(df_test.filename.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-lesbian",
   "metadata": {},
   "source": [
    "### Build datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GemmaDataset(\n",
    "    csv=df_train, \n",
    "    transform=get_train_transform(),\n",
    "    images_path=images_path,\n",
    ")\n",
    "valid_dataset = GemmaDataset(\n",
    "    csv=df_test,\n",
    "    transform=get_valid_transform(),\n",
    "    images_path=images_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    train_dataset[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-clock",
   "metadata": {},
   "source": [
    "### Build loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-cancellation",
   "metadata": {},
   "source": [
    "## Select device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-amount",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets, image_ids = next(iter(train_data_loader))\n",
    "images = list(image.to(device) for image in images)\n",
    "targets = [{k: v.to(device) for k, v in t.items()} for t in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\n",
    "sample = images[0].permute(1,2,0).cpu().numpy()\n",
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "for box in boxes:\n",
    "    cv2.rectangle(\n",
    "        sample,\n",
    "        (box[0], box[1]),\n",
    "        (box[2], box[3]),\n",
    "        (220, 0, 0), \n",
    "        3\n",
    "    )\n",
    "\n",
    "ax.set_axis_off()\n",
    "ax.imshow(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-jimmy",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "lr_scheduler = None\n",
    "\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = Averager()\n",
    "itr = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_hist.reset()\n",
    "    \n",
    "    for images, targets, image_ids in train_data_loader:\n",
    "        \n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        loss_hist.send(loss_value)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % 10 == 0:\n",
    "            print(f\"Iteration #{itr} loss: {loss_value}\")\n",
    "\n",
    "        itr += 1\n",
    "    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    print(f\"Epoch #{epoch} loss: {loss_hist.value}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-nursing",
   "metadata": {},
   "source": [
    "## Save state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_output_path = os.path.join(\"..\", \"models\",datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"state_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    model.state_dict(), \n",
    "    state_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-joshua",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_path = os.path.join(\"..\", \"models\",datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
